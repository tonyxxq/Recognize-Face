{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "args = {}\n",
    "args['dataset'] = \"./images\"\n",
    "args['encodings'] = \"./result\"\n",
    "args['detection_method'] = \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/tonyx/810757517.jpg\n",
      "./images/tonyx/1124417198.jpg\n",
      "./images/tonyx/862179643.jpg\n",
      "./images/tonyx/1009093441.jpg\n",
      "./images/jack_ma/timg2.jpg\n",
      "./images/jack_ma/timg1.jpg\n",
      "./images/jack_ma/timg.jpg\n",
      "./images/jack_ma/jackma.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 对指定路径下的图像人脸进行编码，并存入到磁盘\n",
    "#　--dataset：  数据集的路径（利用search_bing_api.py创建的数据集）；\n",
    "#　--encodings：面部编码将被写到该参数所指的文件中；\n",
    "#　--detection-method：首先需要检测到图像中的面部，才能对其进行编码。两种面部检测方法为hog或cnn，因此该参数只接受这两个值\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--dataset\", required=True, help=\"path to input directory of faces + images\")\n",
    "# ap.add_argument(\"-e\", \"--encodings\", required=True, help=\"path to serialized db of facial encodings\")\n",
    "# ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\", help=\"face detection model to use: either `hog` or `cnn`\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "args = {}\n",
    "args['dataset'] = \"./images\"\n",
    "args['encodings'] = \"./result\"\n",
    "args['detection_method'] = \"hog\"\n",
    "\n",
    "\n",
    "# 获取每一张图像的路径\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# 把每一张图片的名称和编码放到两个数组中\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "\n",
    "# OpenCV中的颜色通道排列顺序为BGR，但dlib要求的顺序为RGB。对每一个图像进行编码。\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # 从文件的路径中获取图片的名称\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    \n",
    "    # 从文件的路径中获取图片的名称\n",
    "    print(imagePath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "     \n",
    "    # 在图片中框出人脸，一幅图像可能有多张人脸\n",
    "    boxes = face_recognition.face_locations(rgb, model=args[\"detection_method\"])\n",
    "     \n",
    "    # 对图片中框处的每张人脸进行编码\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "     \n",
    "    # 把编码结果放到数组中\n",
    "    for encoding in encodings:\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "    \n",
    "# 结果存到磁盘\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "f = open(args[\"encodings\"], \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出图像中的人脸，并进行识别\n",
    "# --encodings：包含面部编码的pickle文件的路径；\n",
    "# --image：    需要进行面部识别的图像；\n",
    "# --detection-method：选择hog或cnn之一。追求速度的话就选择hog，追求准确度就选择cnn。\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-e\", \"--encodings\", required=True,　help=\"path to serialized db of facial encodings\")\n",
    "#ap.add_argument(\"-i\", \"--image\", required=True,　help=\"path to input image\")\n",
    "#ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",　help=\"face detection model to use: either `hog` or `cnn`\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "args[\"image\"] = \"test.jpg\"\n",
    "\n",
    "# 加载已经存储的人脸识别编码数据\n",
    "data = pickle.loads(open(args[\"encodings\"], \"rb\").read())\n",
    "\n",
    "# 加载需要识别的图像，并转换为RGB通道\n",
    "image = cv2.imread(args[\"image\"])\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 检测人脸的位置，并进行编码\n",
    "boxes = face_recognition.face_locations(rgb, model=args[\"detection_method\"])\n",
    "encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "# 保存识别出的人脸的名称\n",
    "names = []\n",
    "\n",
    "\n",
    "# 尝试利用face_recognition.compare_faces将输入图像中的每个面部（encoding）对应到已知的编码数据集（保存在data[\"encodings\"]中）上。\n",
    "# 该函数会返回一个True/False值的列表，每个值对应于数据集中的一张图像。对于我们的侏罗纪公园的例子，数据集中有218张图像，因此返回的列表将包含218个布尔值。\n",
    "# compare_faces函数内部会计算待判别图像的嵌入和数据集中所有面部的嵌入之间的欧几里得距离。\n",
    "# 如果距离位于容许范围内（容许范围越小，面部识别系统就越严格），则返回True，表明面部吻合。否则，如果距离大于容许范围，则返回False表示面部不吻合。\n",
    "for encoding in encodings:\n",
    "    # 当前人脸的编码和库里边的所有的人脸编码进行比对，每一次比对都会返回True，False\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    \n",
    "    # 如果距离位于容许范围内（容许范围越小，面部识别系统就越严格），则返回True，表明面部吻合。否则，如果距离大于容许范围，则返回False表示面部不吻合。\n",
    "    name = \"Unknown\"\n",
    "    if True in matches:\n",
    "        # 把匹配到的人脸的index筛选出来\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "        # 查询出匹配到的人脸的名称\n",
    "        for i in matchedIdxs:\n",
    "            name = data[\"names\"][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "        # 找到匹配度最高的人的名称，作为最终匹配结果\n",
    "        name = max(counts, key=counts.get)\n",
    "\n",
    "    # 添加识别出的人的名称\n",
    "    names.append(name)\n",
    "\n",
    "\n",
    "# 循环每个人的边界盒和名字，然后将名字画在输出图像上以供展示之用：\n",
    "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "    # 画出检测到人脸的矩形框\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "    \n",
    "    # 展示人名，如果边界盒位于图像顶端，则将文本移到边界盒下方，否则文本就被截掉了。\n",
    "    y = top - 15 if top - 15 > 15 else top + 15\n",
    "    cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# 展示输出结果\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import time\n",
    "# 输入参数解析\n",
    "# --output：视频输出路径；\n",
    "# --display：指示是否将视频帧输出到屏幕的标志。1表示显示到屏幕，0表示不显示。\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-e\", \"--encodings\", required=True,　help=\"path to serialized db of facial encodings\")\n",
    "#ap.add_argument(\"-o\", \"--output\", type=str,　help=\"path to output video\")\n",
    "#ap.add_argument(\"-y\", \"--display\", type=int, default=1, help=\"whether or not to display output frame to screen\")\n",
    "#ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",　help=\"face detection model to use: either `hog` or `cnn`\")\n",
    "#args = vars(ap.parse_args())\n",
    "args[\"display\"]=1\n",
    "args[\"output\"]=\"output.mp4\"\n",
    "args[\"detection-method\"]=\"cnn\"\n",
    "\n",
    "# 加载已经保存的编码\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(args[\"encodings\"], \"rb\").read())\n",
    "\n",
    "\n",
    "# 初始化摄像头，启动视频流。如果系统中有多个摄像头（如内置摄像头和外置USB摄像头），可以将src=0改成src=1等，sleep两秒让摄像头预热。\n",
    "print(\"[INFO] starting video stream...\")\n",
    "\n",
    "vs = VideoStream(src=0).start()\n",
    "writer = None\n",
    "time.sleep(2.0)\n",
    "\n",
    "\n",
    "# 抓取视频帧并进行处理\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "    \n",
    "    # convert the input frame from BGR to RGB then resize it to have\n",
    "    # a width of 750px (to speedup processing)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb = imutils.resize(frame, width=750)\n",
    "    r = frame.shape[1] / float(rgb.shape[1])\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input frame, then compute\n",
    "    # the facial embeddings for each face\n",
    "    boxes = face_recognition.face_locations(rgb, model=args[\"detection_method\"])\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    names = []\n",
    "    # loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        # attempt to match each face in the input image to our known\n",
    "        # encodings\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"],  encoding)\n",
    "        name = \"Unknown\"\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            # find the indexes of all matched faces then initialize a\n",
    "            # dictionary to count the total number of times each face\n",
    "            # was matched\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            #loop over the matched indexes and maintain a count for each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            # determine the recognized face with the largest number\n",
    "            # of votes (note: in the event of an unlikely tie Python\n",
    "            # will select first entry in the dictionary)\n",
    "            name = max(counts, key=counts.get)\n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        # rescale the face coordinates\n",
    "        top = int(top * r)\n",
    "        right = int(right * r)\n",
    "        bottom = int(bottom * r)\n",
    "        left = int(left * r)\n",
    "        # draw the predicted face name on the image\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom),(0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
    "        # 保存输出到硬盘，VideoWriter_fourcc。FourCC是一种四字符编码，在这里就是MJPG 四字符编码。\n",
    "        # 接下来将对象、输出路径、每秒帧数的目标值和帧尺寸传递给VideoWriter（行5和6）。\n",
    "        # if the video writer is None *AND* we are supposed to write\n",
    "        # the output video to disk initialize the writer\n",
    "        if writer is None and args[\"output\"] is not None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(args[\"output\"], fourcc, 20,(frame.shape[1], frame.shape[0]), True)\n",
    " \n",
    "    # if the writer is not None, write the frame with recognized\n",
    "    # faces t odisk\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "\n",
    "     # 把视频帧输出到屏幕\n",
    "     # check to see if we are supposed to display the output frame to\n",
    "    # the screen\n",
    "    if args[\"display\"] > 0:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "\n",
    "# 最后的一些清理工作\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "\n",
    "# check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n"
     ]
    }
   ],
   "source": [
    "#from imutils.video import VideoStream\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "# 输入参数解析\n",
    "# --output：视频输出路径；\n",
    "# --display：指示是否将视频帧输出到屏幕的标志。1表示显示到屏幕，0表示不显示。\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-e\", \"--encodings\", required=True,　help=\"path to serialized db of facial encodings\")\n",
    "#ap.add_argument(\"-o\", \"--output\", type=str,　help=\"path to output video\")\n",
    "#ap.add_argument(\"-y\", \"--display\", type=int, default=1, help=\"whether or not to display output frame to screen\")\n",
    "#ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",　help=\"face detection model to use: either `hog` or `cnn`\")\n",
    "#args = vars(ap.parse_args())\n",
    "args[\"display\"]=1\n",
    "args[\"output\"]=\"output.mp4\"\n",
    "args[\"test\"]=\"./test.mp4\"\n",
    "args[\"detection-method\"]=\"hog\"\n",
    "\n",
    "# 加载已经保存的编码\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(args[\"encodings\"], \"rb\").read())\n",
    "\n",
    "vs = cv2.VideoCapture(args[\"test\"])\n",
    "\n",
    "writer = None\n",
    "\n",
    "\n",
    "# 抓取视频帧并进行处理\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "    frame = frame[1]\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    # convert the input frame from BGR to RGB then resize it to have\n",
    "    # a width of 750px (to speedup processing)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb = imutils.resize(frame, width=750)\n",
    "    r = frame.shape[1] / float(rgb.shape[1])\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input frame, then compute\n",
    "    # the facial embeddings for each face\n",
    "    boxes = face_recognition.face_locations(rgb, model=args[\"detection_method\"])\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    names = []\n",
    "    # loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        # attempt to match each face in the input image to our known\n",
    "        # encodings\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"],  encoding)\n",
    "        name = \"Unknown\"\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            # find the indexes of all matched faces then initialize a\n",
    "            # dictionary to count the total number of times each face\n",
    "            # was matched\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            #loop over the matched indexes and maintain a count for each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            # determine the recognized face with the largest number\n",
    "            # of votes (note: in the event of an unlikely tie Python\n",
    "            # will select first entry in the dictionary)\n",
    "            name = max(counts, key=counts.get)\n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        # rescale the face coordinates\n",
    "        top = int(top * r)\n",
    "        right = int(right * r)\n",
    "        bottom = int(bottom * r)\n",
    "        left = int(left * r)\n",
    "        # draw the predicted face name on the image\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom),(0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
    "        # 保存输出到硬盘，VideoWriter_fourcc。FourCC是一种四字符编码，在这里就是MJPG 四字符编码。\n",
    "        # 接下来将对象、输出路径、每秒帧数的目标值和帧尺寸传递给VideoWriter（行5和6）。\n",
    "        # if the video writer is None *AND* we are supposed to write\n",
    "        # the output video to disk initialize the writer\n",
    "        if writer is None and args[\"output\"] is not None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(args[\"output\"], fourcc, 20,(frame.shape[1], frame.shape[0]), True)\n",
    " \n",
    "    # if the writer is not None, write the frame with recognized\n",
    "    # faces t odisk\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "\n",
    "     # 把视频帧输出到屏幕\n",
    "     # check to see if we are supposed to display the output frame to\n",
    "    # the screen\n",
    "    if args[\"display\"] > 0:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "\n",
    "# 最后的一些清理工作\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "    writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
